{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccb0cc-8429-42f5-bc7f-1add7293c1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyreadr as py\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix,confusion_matrix,classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7795930-b00e-4b10-9b8d-4174be1bde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    # Convertir las probabilidades predichas en clases\n",
    "    print(predict_y.shape)\n",
    "    print(test_y.shape)\n",
    "    #if len(predict_y.shape) == 1:\n",
    "    #    predict_y_classes = predict_y.reshape(-1, 1)\n",
    "    #else:\n",
    "    #    predict_y_classes = np.argmax(predict_y, axis=1)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    C = confusion_matrix(test_y, predict_y_classes)\n",
    "    \n",
    "    # Calcular la precisión y recall\n",
    "    A = (((C.T) / (C.sum(axis=1))).T)\n",
    "    B = (C / C.sum(axis=0))\n",
    "    \n",
    "    labels = [0,1,2,4,5,6,7,8,10,11,12,13,14,16,17,18,19,20]\n",
    "    cmap = sns.color_palette(\"Greens\", as_cmap=True)\n",
    "    \n",
    "    # Representar la matriz de confusión en formato de heatmap\n",
    "    print(\"-\" * 50, \"Confusion matrix\", \"-\" * 50)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.savefig(f'matrices/confusion_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Representar la matriz de precisión en formato de heatmap\n",
    "    print(\"-\" * 50, \"Precision matrix\", \"-\" * 50)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.savefig(f'matrices/precision_matrix.png')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # Representar la matriz de recall en formato de heatmap\n",
    "    print(\"-\" * 50, \"Recall matrix\", \"-\" * 50)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.savefig(f'matrices/recall_matrix.png')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7587a-63f7-4dc6-8533-22433562d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "cv = pd.read_csv(\"cv.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fd86c-e3c5-4ef4-af96-815bff48e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the sampled train data:\", train.shape)\n",
    "print(\"Shape of the sampled test data:\", test.shape)\n",
    "print(\"Shape of the sampled CV data:\", cv.shape)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75454a4-d1ce-4252-a0d4-36c0f61362d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing faults 3,9 and 15 \n",
    "tr = train.drop(train[(train.faultNumber == 3) | (train.faultNumber == 9) | (train.faultNumber == 15)].index).reset_index()\n",
    "ts = test.drop(test[(test.faultNumber == 3) | (test.faultNumber == 9) | (test.faultNumber == 15)].index).reset_index()\n",
    "cv_ = cv.drop(cv[(cv.faultNumber == 3) | (cv.faultNumber == 9) | (cv.faultNumber == 15)].index).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738b416-db3f-40e0-a206-3bc64b44e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "# Resizing the train, test and cv data.\n",
    "x_train = np.resize(tr,(183200,52))\n",
    "x_test = np.resize(ts,(89000,52))\n",
    "x_cv = np.resize(cv_,(93440,52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63478697-ae76-4e1c-82bf-251d17e2fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e8325-6012-449d-aebd-5435cc03cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the class labels to categorical values and removing unnecessary features from train, test and cv data.\n",
    "y_train = tr['faultNumber']\n",
    "y_test = ts['faultNumber']\n",
    "y_cv = cv_['faultNumber']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajustar y transformar los datos de salida\n",
    "y_train_encoded = encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test_encoded = encoder.fit_transform(np.array(y_test).reshape(-1, 1))\n",
    "y_cv_encoded = encoder.fit_transform(np.array(y_cv).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b8e62-3f8a-4376-adb6-f1f8facedabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.drop(['faultNumber','Unnamed: 0','simulationRun','sample','index'],axis=1,inplace=True)\n",
    "ts.drop(['faultNumber','Unnamed: 0','simulationRun','sample','index'],axis =1,inplace=True)\n",
    "cv_.drop(['faultNumber','Unnamed: 0','simulationRun','sample','index'],axis =1,inplace=True)\n",
    "standard_scalar = StandardScaler()\n",
    "train_norm = standard_scalar.fit_transform(tr)\n",
    "test_norm = standard_scalar.transform(ts)\n",
    "cv_norm = standard_scalar.transform(cv_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb40a1-0693-4169-bc19-cca37576a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1419b-8c45-4b4b-ae82-22da79f606f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int('units', min_value=32, max_value=256, step=32),\n",
    "                                    activation=hp.Choice('input_activation', values=['relu', 'elu'])))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int('units', min_value=32, max_value=256, step=32),\n",
    "                                    activation=hp.Choice('input_activation', values=['relu', 'elu'])))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int(f'layer_{i}_units', min_value=32, max_value=256, step=32),\n",
    "                                        activation=hp.Choice(f'layer_{i}_activation', values=['tanh', 'sigmoid'])))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(18, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adamw',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def optimize_hyperparameters(train_data, train_labels, val_data, val_labels, max_epochs=10, batch_size=32):\n",
    "    if not os.path.exists('hiperParametros'):\n",
    "        os.makedirs('hiperParametros')\n",
    "\n",
    "    tuner = kt.Hyperband(build_model,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=max_epochs,\n",
    "                         factor=3,\n",
    "                         directory='hiperParametros',\n",
    "                         project_name='hiperparametrosKeras')\n",
    "\n",
    "    tuner.search(train_data, train_labels, epochs=max_epochs, batch_size=batch_size, validation_data=(val_data, val_labels))\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # Imprimir los mejores hiperparámetros\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    for param in best_hps.values.keys():\n",
    "        print(f\"{param}: {best_hps.get(param)}\")\n",
    "\n",
    "    print(\"\\nLayer-wise Hyperparameter Information:\")\n",
    "    layer_index = 0\n",
    "    for hp in tuner.oracle.hyperparameters.space:\n",
    "        print('----------------------')\n",
    "        print(list(hp.values))\n",
    "       \n",
    "    return best_hps\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "# Inicialización del optimizador\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.mean_squared_error\n",
    "mean_loss = tf.keras.metrics.Mean(name=\"mean_loss\")\n",
    "accuracy = tf.keras.metrics.Accuracy(name=\"accuracy\")  # Nueva métrica de accuracy\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "# Ejemplo de uso:\n",
    "best_hyperparameters = optimize_hyperparameters(train_norm, y_train_encoded.toarray(), cv_norm, y_cv_encoded.toarray())\n",
    "\n",
    "\n",
    "model = build_model(best_hyperparameters)    \n",
    "\n",
    "# Entrena el modelo\n",
    "history = model.fit(train_norm, y_train_encoded.toarray(), epochs=5, batch_size=32, validation_data=(cv_norm, y_cv_encoded.toarray()))\n",
    "\n",
    "# Evalúa el modelo\n",
    "accuracy = model.evaluate(test_norm, y_test_encoded.toarray())[1]\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb79e3e-2b03-44de-9635-bc435875dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Obtener las probabilidades predichas del modelo\n",
    "predict_y_prob = model.predict(test_norm)\n",
    "\n",
    "# Convertir las probabilidades predichas en clases\n",
    "predict_y_classes = np.argmax(predict_y_prob, axis=1)\n",
    "\n",
    "predict_y_multilabel = np.argmax(predict_y_prob, axis=1)\n",
    "\n",
    "# Convertir las clases predichas a un formato multilabel-indicator\n",
    "#predict_y_multilabel = label_binarize(predict_y_classes, classes=np.unique(y_test_encoded))\n",
    "\n",
    "# Llamar a la función plot_confusion_matrix con las etiquetas verdaderas y las predicciones\n",
    "plot_confusion_matrix(np.argmax(y_test_encoded.toarray(), axis=1), predict_y_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca23fd-23a0-4b75-b032-dc7f163c36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(test_norm, columns=['xmeas_1',\n",
    " 'xmeas_2',\n",
    " 'xmeas_3',\n",
    " 'xmeas_4',\n",
    " 'xmeas_5',\n",
    " 'xmeas_6',\n",
    " 'xmeas_7',\n",
    " 'xmeas_8',\n",
    " 'xmeas_9',\n",
    " 'xmeas_10',\n",
    " 'xmeas_11',\n",
    " 'xmeas_12',\n",
    " 'xmeas_13',\n",
    " 'xmeas_14',\n",
    " 'xmeas_15',\n",
    " 'xmeas_16',\n",
    " 'xmeas_17',\n",
    " 'xmeas_18',\n",
    " 'xmeas_19',\n",
    " 'xmeas_20',\n",
    " 'xmeas_21',\n",
    " 'xmeas_22',\n",
    " 'xmeas_23',\n",
    " 'xmeas_24',\n",
    " 'xmeas_25',\n",
    " 'xmeas_26',\n",
    " 'xmeas_27',\n",
    " 'xmeas_28',\n",
    " 'xmeas_29',\n",
    " 'xmeas_30',\n",
    " 'xmeas_31',\n",
    " 'xmeas_32',\n",
    " 'xmeas_33',\n",
    " 'xmeas_34',\n",
    " 'xmeas_35',\n",
    " 'xmeas_36',\n",
    " 'xmeas_37',\n",
    " 'xmeas_38',\n",
    " 'xmeas_39',\n",
    " 'xmeas_40',\n",
    " 'xmeas_41',\n",
    " 'xmv_1',\n",
    " 'xmv_2',\n",
    " 'xmv_3',\n",
    " 'xmv_4',\n",
    " 'xmv_5',\n",
    " 'xmv_6',\n",
    " 'xmv_7',\n",
    " 'xmv_8',\n",
    " 'xmv_9',\n",
    " 'xmv_10',\n",
    " 'xmv_11'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2fbd4-662c-4c7e-a44e-f38850c23ea3",
   "metadata": {},
   "source": [
    "### Partial Dependence Plot (PDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5672438-b941-4abf-b213-7bac1830dc93",
   "metadata": {},
   "source": [
    "El gráfico de dependencia parcial PDP son gráficos que nos ayudan a entender cómo una variable específica afecta a las predicciones de nuestro modelo.\n",
    "\n",
    "-  Para construir una PDP debemos elegir la característica de entrada que será la que queramos analizar.\n",
    "- Variamos su valor, es decir, mantenemos constantes todas las demás variables y modificamos gradualmente el valor de la variable seleccionada.\n",
    "- Calculamos las predicciones, es decir, para cada valor de la variable calculamos las predicciones del modelo.\n",
    "- Graficamos estos resultados. Representamos en un gráfico cómo cambian las predicciones a medida que varia la variable\n",
    "\n",
    "El eje x representa los valores de la variable (característica) seleccionada, y el eje y muestra las predicciones del modelo.\n",
    "\n",
    "Una vez que tengamos las gráficas dibujadas podremos analizarlas para ver como se comportan. Si la curva es lineal, significa que la relación entre la variable y la predicción es aditiva. Es decir no hay muchas interacciones con otras características. Mientras que si no ocurre esto, podría significar que la característica es dependiente de otras características del conjunto.\n",
    "\n",
    "Las PDP asumen que las variables no están correlacionadas, ya que si hay variables correlacionadas los resultados puedes resultar engañosos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d22b69-0305-4466-825d-0082fafc2afe",
   "metadata": {},
   "source": [
    "Para poder abordar las PDP de forma matemática debemos presentar algunas definiciones.\n",
    "\n",
    "- $\\textit{Modelo de regresión}$. Un modelo de regresión es un enfoque estadístico usado para modelar y analizar la relación entre una o más variables independientes (características) y una variablbe dependiente continua. La idea principal de este modelo es predecir o estimar el valor de la variable dependiente en función de los valores de las variables independientes.\n",
    "- En este modelo, podemos expresar la relación entre las variables independientes y la dependiente mediante una función matemática. Esta función se usa para realizar las predicciones sobre la variable dependiente en funcionn de los valores de las variables independientes.\n",
    "\n",
    "Existen varios tipos de modelos de regresión, cada uno de los cuales usa diferentes funciones matemáticas para modelar la relación entre las varibales. Entre ellos encontramos la regresión lineal, regresión polinómica, regresión logística y regresión de árbol de decisiones. \n",
    "\n",
    "\n",
    "Ahora supongamos que tenemos nuetra función de predicción del modelo $f(x)$ que predice una variable de respuesta $Y$ en función de $C$ características de entrada $X=(X_1, X_2, X_3,....)$\n",
    "\n",
    "El objetivo que se busca a través de las PDP es visualizar como cambia la predicción del modelo $f(x)$ cuando variamos una o varias características de entrada $X_S$, manteniendo el resto de características constantes o promediadas.\n",
    "\n",
    "\n",
    "La función de la dependencia parcial $PD_S(x_S)$ para una característica $X_S$ se define como \n",
    "$$PD_S(x_S)=E_{X_C}[f(x_S, X_C)] = \\int f(x_S, x_c)d\\mathbb{P}(X_C)$$\n",
    "\n",
    "Donde \n",
    "\n",
    "- $PD_S(x_S)$ es la función dependencia parcial para las características $X_S$\n",
    "- $E_{X_C}$ es el valor esperado sobre todas las características $X_C$ excepto $X_S$.\n",
    "- $f(x)$ es el modelo de aprendizaje automático\n",
    "- $x_S$ son las características para las cuales se debe trazar la función de dependencia parcia\n",
    "- $x_c$ son el resto de características usadas en el modelo $f(x)$ \n",
    "\n",
    "Normalmente hay una o dos características en el conjunto $S$. Las características en $S$ son aquellas para las cuales queremos saber el efecto en la predicción. Los vectores $x_S$ y $x_C$ combinados forman el espacio total de características $x$\n",
    "\n",
    "La función de dependencia parcial funciona marginalizando la salida del modelo de aprendizaje automático sobre la distribución de las características en el conjunto $C$, de modo que la función muestre la relación entre las características en el conjunto $S$ que nos interesan y el resultado predicho. Al marginalizar sobre las otras características, obtenemos una función que depende solo de las características en $S$, incluidas las interacciones con otras características.\n",
    "\n",
    "La función $f_S(x_S)$ se estima calculando promedios en los datos de entrenamiento, también conocido como método de Monte Carlo:\n",
    "$$f_S=\\frac{1}{n}\\sum_{i=1}^n f(x_S,x_C^{(i)})$$\n",
    "Esta función nos dice, para un valor dado de las características $S$, cuál es el efecto marginal promedio en la predicción. En esta fórmula, $x_C^{(i)}$ son los valores reales de las características del conjunto de datos para las características en las que no estamos interesados, y $n$ es el número de instancias en el conjunto de datos. Para que este método funcione bien, se debe suponer que las características en $C$ no están correlacionadas con las características en $S$, de otra forma los resultados pueden verse afectados.\n",
    "\n",
    "En el caso de la clasificación, donde el modelo de aprendizaje automático produce probabilidades, el gráfico de dependencia parcial muestra la probabilidad de cierta clase dada diferentes valores para las características en $S$. Una forma fácil de manejar múltiples clases es dibujar una línea o gráfico por clase.\n",
    "\n",
    "El gráfico de dependencia parcial es un método global: considera todas las instancias y proporciona una declaración sobre la relación global de una característica con el resultado predicho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5510f75-e891-4009-8f67-617aa5e160d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac8462-dc64-4ef0-8fb6-918917fd6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummy_pdp(salida):\n",
    "    class clf_dummy():\n",
    "        def __init__(self, model, salida):\n",
    "            self.model = model\n",
    "            self.salida = salida\n",
    "\n",
    "        def __call__(self, df):\n",
    "            return self.model.predict(df)[:, self.salida]\n",
    "    \n",
    "    return clf_dummy(model, salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567f795-3d06-49f8-9815-a0e0c083c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de características\n",
    "features = ['xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', \n",
    "            'xmeas_7', 'xmeas_8', 'xmeas_9', 'xmeas_10', 'xmeas_11', 'xmeas_12', \n",
    "            'xmeas_13', 'xmeas_14', 'xmeas_15', 'xmeas_16', 'xmeas_17', 'xmeas_18', \n",
    "            'xmeas_19', 'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', \n",
    "            'xmeas_25', 'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', \n",
    "            'xmeas_31', 'xmeas_32', 'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36', \n",
    "            'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_40', 'xmeas_41', 'xmv_1', \n",
    "            'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', \n",
    "            'xmv_10', 'xmv_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac2001-e72c-42ed-b4ae-060b2947aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se va a pintar en cada gráfica como afecta cada característica a cada uno de los ataques\n",
    "#52 gráficas, con 18 curvas cada una\n",
    "for feature in features:\n",
    "    fig, ax = plt.subplots(figsize=(20, 25))\n",
    "    for i in range(0,18):\n",
    "        model_pdp=make_dummy_pdp(feature)\n",
    "        print('PDP - feature ', feature)\n",
    "        shap_line = shap.plots.partial_dependence(\n",
    "            feature,model_pdp, temp, ice=False,\n",
    "            model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "        )\n",
    "        shap_line[0].set_label(f'Ataque {i+1}')\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"images/pdp/ataque{i}.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73a49e-d206-45c8-af17-283fc2f3caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a plotear las 2D PDP para el ataque 4\n",
    "model_pdp=make_dummy_pdp(3)\n",
    "attack_pairs =  [('xmeas_13', 'xmv_7'),\n",
    "('xmeas_18', 'xmv_3'),\n",
    "('xmeas_6', 'xmeas_7'),\n",
    "('xmeas_6', 'xmeas_14'),\n",
    "('xmeas_19', 'xmeas_5'),\n",
    "('xmeas_1', 'xmeas_36'),\n",
    "('xmeas_29', 'xmv_6'),\n",
    "('xmeas_27', 'xmeas_9'),\n",
    "('xmeas_34', 'xmv_8'),\n",
    "('xmeas_15', 'xmeas_4'),\n",
    "('xmeas_30', 'xmeas_29'),\n",
    "('xmeas_23', 'xmeas_28'),\n",
    "('xmeas_7', 'xmeas_30'),\n",
    "('xmeas_3', 'xmv_2'),\n",
    "('xmeas_24', 'xmv_1'),\n",
    "('xmeas_29', 'xmeas_17'),\n",
    "('xmeas_38', 'xmeas_40'),\n",
    "('xmeas_11', 'xmv_4'),\n",
    "('xmeas_20', 'xmv_5'),\n",
    "('xmeas_26', 'xmeas_35')]\n",
    "\n",
    "for attack1, attack2 in attack_pairs:\n",
    "    print(f'PDP - attacks {attack1} and {attack2}')\n",
    "    fig, ax = plt.subplots()\n",
    "    shap.plots.partial_dependence(\n",
    "        (attack1, attack2), model_pdp, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    fig.savefig(f\"images/pdp2D/attacks{attack1}and{attack2}.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644ffe7-2584-45ad-bcc2-ce50c1ab2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a pintar los plot de los siguientes ataques:\n",
    "#Ataque 1\n",
    "model_pdp_0=make_dummy_pdp(0)\n",
    "for feature in features:\n",
    "    print('PDP - feature ', feature)\n",
    "    fig, ax = plt.subplots()\n",
    "    shap.plots.partial_dependence(\n",
    "        feature,model_pdp_0, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    fig.savefig(f\"images/pdp/ataque1/ataque1_{feature}.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e315c-8773-44ec-ac62-5182e68c3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ataque 2\n",
    "model_pdp_1=make_dummy_pdp(1)\n",
    "for feature in features:\n",
    "    print('PDP - feature ', feature)\n",
    "    fig, ax = plt.subplots()\n",
    "    shap.plots.partial_dependence(\n",
    "        feature,model_pdp_1, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    fig.savefig(f\"images/pdp/ataque2/ataque2_{feature}.png\")\n",
    "    plt.show()  # Mostrar la figura\n",
    "    plt.close(fig)  # Cerrar la figura para liberar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120f907-2788-4c93-8b3f-2597e6d6bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ataque 3\n",
    "model_pdp_2=make_dummy_pdp(2)\n",
    "for feature in features:\n",
    "    print('PDP - feature ', feature)\n",
    "    shap.plots.partial_dependence(\n",
    "        feature,model_pdp_2, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    fig.savefig(f\"images/pdp/ataque3/ataque3_{feature}.png\")\n",
    "    plt.show()  # Mostrar la figura\n",
    "    plt.close(fig)  # Cerrar la figura para liberar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367045f-c14e-47fb-8e1d-c9236a0fc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ataque 4\n",
    "model_pdp_3=make_dummy_pdp(3)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for feature in features:\n",
    "    print('PDP - feature ', feature)\n",
    "    shap.plots.partial_dependence(\n",
    "        feature,model_pdp_3, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    fig.savefig(f\"images/pdp/ataque4/ataque4_{feature}.png\")\n",
    "    plt.show()  # Mostrar la figura\n",
    "    plt.close(fig)  # Cerrar la figura para liberar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb7574-6a6c-40ec-bd0b-2ff3bddc0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pdp_13=make_dummy_pdp(12)\n",
    "\n",
    "attack_pairs = [('xmeas_20', 'xmeas_21'), ('xmeas_11', 'xmv_3')]  # Reemplaza con los nombres de tus ataques\n",
    "for attack1, attack2 in attack_pairs:\n",
    "    print(f'PDP - attacks {attack1} and {attack2}')\n",
    "    fig, ax = plt.subplots()\n",
    "    shap.plots.partial_dependence(\n",
    "        (attack1, attack2), model_pdp_13, temp, ice=False,\n",
    "        model_expected_value=True, feature_expected_value=True, show=False, ax=ax\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1ec35-8483-4d1a-bafa-97d967f26061",
   "metadata": {},
   "source": [
    "### Accumulated Local Effects (ALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453b72d-48b6-4f61-995f-b9a61d228c2f",
   "metadata": {},
   "source": [
    "Los Accumulated Local Effects (ALE) Plots emergen como una herramienta robusta para interpretar modelos complejos, proporcionando insights sobre la influencia de características individuales en las predicciones del modelo. Este método es particularmente efectivo en contextos donde las características predictivas están correlacionadas, superando algunas limitaciones de los métodos tradicionales como los Partial Dependence Plots (PDPs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19296264-d58a-4837-a01e-a31683613314",
   "metadata": {},
   "source": [
    "##### Importancia de los ALE Plots en el Análisis de TEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba62aa-b674-4f42-befc-ce660a0773fe",
   "metadata": {},
   "source": [
    "Dado que el conjunto de datos TEP incluye múltiples variables altamente correlacionadas que afectan el rendimiento del proceso, es fundamental emplear métodos de interpretación que puedan manejar adecuadamente estas correlaciones para evitar conclusiones erróneas. Los ALE plots, que se centran en evaluar los efectos locales acumulativos de las características, proporcionan una visión clara y matizada de cómo cambios específicos en variables del proceso impactan las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d742e-330a-4fc6-b9f0-6e69db4b1a29",
   "metadata": {},
   "source": [
    "#### Desarrollo Matemático de los ALE Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fa1c9-b946-49b2-a7db-bb1ea8994066",
   "metadata": {},
   "source": [
    "Los ALE plots ofrecen un enfoque refinado para evaluar la importancia de las características en un modelo predictivo, especialmente útil cuando estas características están correlacionadas entre sí. Este método enfatiza el efecto local de las características, proporcionando una perspectiva detallada sobre cómo pequeñas variaciones en una característica específica influyen en las predicciones del modelo. A continuación, se proporciona una descripción ampliada de cada etapa del proceso matemático implicado en la construcción de un ALE plot, ofreciendo una interpretación profunda y precisa de las fórmulas y procesos utilizados.\n",
    "\n",
    "- $\\textit{Definición y Particionamiento de la Característica de Interés}$: Para implementar un ALE plot, primero es necesario seleccionar una característica $S$ del modelo que deseamos analizar. El rango de $S$ se divide en $k$ intervalos discretos, definidos cada uno por un par de valores $(z_{S,i−1},z_{S,i})$. Esta división permite evaluar el impacto incremental de $S$ en segmentos manejables, facilitando un análisis detallado del comportamiento de la función de predicción $f$ en diferentes partes de su dominio.\n",
    "  \n",
    "    - $\\textit{Importancia del Tamaño de Intervalo}$: La elección del número de intervalos $k$ y su tamaño puede influir significativamente en la resolución y suavidad del ALE plot resultante. Intervalos más pequeños pueden capturar variaciones más finas en el efecto de $S$, pero también pueden llevar a una mayor variabilidad en las estimaciones de los efectos locales debido a un menor número de datos en cada intervalo.\n",
    "\n",
    "-  $\\textit{Cálculo de Efectos Locales Promedio}$: Para cada intervalo, se calcula el cambio promedio en la predicción causado por cambios dentro del intervalo. Esto se logra a través de la siguiente expresión integral:\n",
    "    $$ALE_{S,i} = \\int_{z_{S,i-1}}^{z_{S,i}}\\left( \\int_{X_C} \\frac{\\partial f(z_S,X_C)}{\\partial z_S} dP(X_C|X_S = z_S)\\right) dz_S$$\n",
    "\n",
    "    donde:\n",
    "      - La integral interna calcula el promedio de la derivada parcial de $f$ respecto a $S$, ponderada por la distribución condicional de las otras características $X_C$. Este término $\\frac{\\partial f(z_S,X_C)}{\\partial z_S} $ representa la sensibilidad de la función de predicción a cambios infinitesimales en $S$, evaluada en cada punto $z_S$ dentro del intervalo.\n",
    "        \n",
    "      - Integración Externa: La integral externa acumula estos efectos locales sobre el intervalo $(z_{S,i−1},z{S,i})$, proporcionando una medida del impacto total de las variaciones en $S$ dentro de ese segmento específico. \n",
    "\n",
    "- $\\textit{Acumulación de Efectos Locales}$ para obtener el efecto acumulativo total de la característica $S$ hasta cualquier valor $x_S$, se suman todos los efectos locales calculados para los intervalos hasta $x_S$\n",
    "$$ALE_S(x_S) = \\sum_{i:z_{S,i}\\leq x_S} ALE_{S,i} - \\text{constante}$$\n",
    "\n",
    "- $\\textit{Ajuste de la Constante}$: La constante en la fórmula es esencial para centrar los valores del ALE plot alrededor de cero. Esto se logra asegurando que el valor medio del ALE plot a lo largo de todos los valores posibles de $S$ sea cero, lo cual mejora la interpretabilidad al establecer un punto de referencia neutral para evaluar los efectos de $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cb397-8db0-4034-8676-c8e1c0d0145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Función de envoltura para el método predict del modelo Keras\n",
    "def predict_proba_wrapper(data):\n",
    "    return model.predict(data)\n",
    "\n",
    "# Inicializar el explicador LIME\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=temp.values,\n",
    "    feature_names=temp.columns,\n",
    "    class_names=features,  # Ajusta los nombres de las clases según tu modelo\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Seleccionar una instancia para explicar (por ejemplo, la primera instancia del conjunto de datos)\n",
    "instance = temp.iloc[0]\n",
    "\n",
    "# Generar la explicación para la instancia seleccionada\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=instance,\n",
    "    predict_fn=predict_proba_wrapper\n",
    ")\n",
    "\n",
    "# Dibujar y guardar la explicación\n",
    "fig = exp.as_pyplot_figure()\n",
    "fig.savefig(f\"{output_dir}/lime_explanation_instance_0.png\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# Si deseas generar explicaciones para múltiples instancias\n",
    "for i in range(len(temp)):\n",
    "    instance = temp.iloc[i]\n",
    "    exp = explainer.explain_instance(\n",
    "        data_row=instance,\n",
    "        predict_fn=predict_proba_wrapper\n",
    "    )\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.savefig(f\"{output_dir}/lime_explanation_instance_{i}.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b6619-4e6d-458c-a80d-40b60abc5e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
